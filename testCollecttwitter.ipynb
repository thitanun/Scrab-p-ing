{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Teaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Teaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "nltk.download('punkt')   \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize as nltk_wt\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime,timedelta ,date\n",
    "# from pythainlp.corpus import thai_stopwords\n",
    "from pythainlp import word_tokenize as pyt_wt\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'xxxx'\n",
    "consumer_secret= 'xxxx'\n",
    "access_token= 'xxxx'\n",
    "access_token_secret= 'xxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClawTwitter:\n",
    "    def __init__(self, keyw:str): \n",
    "        self.listdata = []\n",
    "        self.keyword = keyw\n",
    "        self.data = self.get_datatweet()\n",
    "        self.metadata = {}\n",
    "        self.setup_dir()\n",
    "        self.load_metadata()\n",
    "\n",
    "    def setup_dir(self):\n",
    "        if not os.path.exists(f\"./data/\"): \n",
    "            os.mkdir(f\"./data/\")\n",
    "        if not os.path.exists(f\"./data/tweets/\"): \n",
    "            os.mkdir(f\"./data/tweets/\")\n",
    "            # print(\"crete success\")\n",
    "        if not os.path.exists('./data/metadata.json'):\n",
    "            data = {'keyword' : {}}\n",
    "            with open('./data/metadata.json', 'w', encoding=\"UTF-8\") as file: #utf-16\n",
    "                metafile = json.dumps(data, indent=4)\n",
    "                file.write(metafile)\n",
    "        \n",
    "    def load_metadata(self):\n",
    "        metadata_json = open('./data/metadata.json',encoding=\"UTF-8\")\n",
    "        self.metadata = json.load(metadata_json)\n",
    "\n",
    "    def save_metadata(self):\n",
    "        with open('./data/metadata.json', 'w', encoding=\"UTF-8\") as file:\n",
    "            metafile = json.dumps(self.metadata, indent=4)\n",
    "            file.write(metafile)\n",
    "\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "            auth.set_access_token(access_token, access_token_secret)\n",
    "            api = tw.API(auth)\n",
    "            return api\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "            exit(1)\n",
    "\n",
    "    def remove_url(txt):\n",
    "        \"\"\"Replace URLs found in a text string with nothing \n",
    "        (i.e. it will remove the URL from the string).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        txt : string\n",
    "            A text string that you want to parse and remove urls.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The same txt string with url's removed.\n",
    "        \"\"\"\n",
    "\n",
    "        return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "\n",
    "    def remove_url_th(txt):\n",
    "        \"\"\"Replace URLs found in a text string with nothing \n",
    "        (i.e. it will remove the URL from the string).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        txt : string\n",
    "            A text string that you want to parse and remove urls.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The same txt string with url's removed.\n",
    "        \"\"\"\n",
    "\n",
    "        return \" \".join(re.sub(\"([^\\u0E00-\\u0E7Fa-zA-Z' ]|^'|'$|''|(\\w+:\\/\\/\\S+))\", \"\", txt).split())\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'(@[A-Za-z0-9_]+)', '', text)\n",
    "        text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text_tokens = nltk_wt(text)\n",
    "        text = [word for word in text_tokens if not word in stopwords.words()]\n",
    "        text = ' '.join(text)\n",
    "        return text\n",
    "\n",
    "\n",
    "    def clean_text_th(self, text):\n",
    "        text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "        url = \"https://api.aiforthai.in.th/textcleansing\"\n",
    "        params = {f'text':{text}}\n",
    "        headers = {\n",
    "            'Apikey': \"xxxx\",\n",
    "            }\n",
    "        res = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "        # print('test sen', res.json())\n",
    "        return res.json()['cleansing_text']\n",
    "\n",
    "\n",
    "    def stemmer(self, text):\n",
    "        porter_text = PorterStemmer()\n",
    "        token_words = nltk_wt(text)\n",
    "        stem_word = []\n",
    "        for word in token_words:\n",
    "            stem_word.append(porter_text.stem(word))\n",
    "        return \" \".join(stem_word)\n",
    "\n",
    "\n",
    "    def sentiment(self, text_en):\n",
    "        sentiment_text = text_en.sentiment.polarity\n",
    "        if  sentiment_text > 0:\n",
    "            return 'positive'\n",
    "        elif sentiment_text < 0:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "\n",
    "\n",
    "    def sentiment_th(self, text_th):\n",
    "        url = \"https://api.aiforthai.in.th/ssense\"\n",
    "        params = {'text':text_th}\n",
    "        headers = {\n",
    "            'Apikey': \"xxxx\"\n",
    "            }\n",
    "        res = requests.get(url, headers=headers, params=params)\n",
    "        if res.json()['sentiment']['polarity'] == '':\n",
    "            polarity = \"neutral\"\n",
    "        else:\n",
    "            polarity = res.json()['sentiment']['polarity']\n",
    "        # print('hey', res.json())\n",
    "        return polarity\n",
    "\n",
    "\n",
    "    def get_datatweet(self):\n",
    "        if not os.path.exists(f\"./data/tweets/{self.keyword}\"):\n",
    "            os.makedirs(f\"./data/tweets/{self.keyword}\")\n",
    "        api = self.connect()\n",
    "        today = datetime.utcnow().date()\n",
    "        today_str = today.strftime(\"%Y-%m-%d\")\n",
    "        tweets = tw.Cursor(api.search_tweets,\n",
    "                    q=self.keyword + \" -filter:retweets\",\n",
    "                    since= today_str).items(100)\n",
    "                    # since= today_str).items(10)\n",
    "                     \n",
    "        tweet_list = []    \n",
    "        for tweet in tweets:\n",
    "            tweet_list.append(tweet)\n",
    "        tweets = tweet_list\n",
    "\n",
    "        data_tweet = [[self.keyword,\n",
    "                        tweet.user.screen_name,\n",
    "                        # tweet.lang,\n",
    "                        tweet.user.location if tweet.user.location != '' else 'unknown',\n",
    "                        tweet.created_at.replace(tzinfo = None) + timedelta(hours = 7),\n",
    "                        ClawTwitter.remove_url(tweet.text) if tweet.lang == \"en\" else ClawTwitter.remove_url_th(tweet.text),\n",
    "                        tweet.retweet_count,\n",
    "                        tweet.favorite_count,\n",
    "                        # self.count_for_data(self.data_hashtagcount()),\n",
    "                        # self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text))))),\n",
    "                        # self.sentiment(TextBlob(self.stemmer(ClawTwitter.remove_url(tweet.text)))),\n",
    "                        self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text)))))\n",
    "                                        if tweet.lang == \"en\" else self.sentiment_th(self.clean_text_th(tweet.text)),\n",
    "                        # self.sentiment_th(tweet.text) if tweet.lang == \"th\"\n",
    "                        #             else self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text))))),\n",
    "                        f\"https://twitter.com/twitter/statuses/{tweet.id}\"] for tweet in tweets]\n",
    "\n",
    "        return data_tweet\n",
    "\n",
    "\n",
    "    def show_data(self, data_tweet:list):\n",
    "        tweet_frame = pd.DataFrame(data=data_tweet,\n",
    "                            # columns=['topic', 'user','language','location','post date', 'tweet','retweet','likes', 'sentiment','tweet link'])\n",
    "                            # columns=['topic', 'user','location','post date', 'tweet','retweet','likes', 'count', 'sentiment','tweet link'])\n",
    "                            columns=['topic', 'user','location','post date', 'tweet','retweet','likes', 'sentiment','tweet link'])\n",
    "        \n",
    "        # tweet_frame.to_excel(f\"{self.keyword}.xlsx\", engine=\"openpyxl\", index=False)\n",
    "        return tweet_frame\n",
    "\n",
    "\n",
    "    def twitter_to_xlsx(self, tweets):\n",
    "        hashtag = self.keyword\n",
    "        today = date.today()\n",
    "        today_str = today.strftime(\"%d%m%Y\")\n",
    "        # if not os.path.exists(f\"./data/tweets/{hashtag}\"):\n",
    "        #     os.makedirs(f\"./data/tweets/{hashtag}\")\n",
    "        if hashtag not in self.metadata['keyword'].keys():\n",
    "            self.metadata['keyword'][hashtag] = {'date' : []}\n",
    "        # tweets.to_excel(hashtag+\"_\"+today_str+\".xlsx\", engine=\"openpyxl\", index=False)\n",
    "        tweets.to_excel(f\"./data/tweets/{hashtag}/{hashtag}_{today_str}.xlsx\", engine=\"openpyxl\", index=False)\n",
    "        if today_str not in self.metadata['keyword'][hashtag]['date']:\n",
    "            self.metadata['keyword'][hashtag]['date'].append(today_str)\n",
    "            self.save_metadata()\n",
    "    \n",
    "\n",
    "    def data_hashtagcount(self):\n",
    "        api = self.connect()\n",
    "        today = datetime.utcnow().date()\n",
    "        today_str = today.strftime(\"%Y-%m-%d\")\n",
    "        new_column = []\n",
    "        for tweet in tw.Cursor(api.search_tweets,\n",
    "                    q=self.keyword + \" -filter:retweets\",\n",
    "                    since= today_str).items(100):\n",
    "            entity_ht = tweet.entities.get('hashtags')\n",
    "            hashtag = \"\"\n",
    "            for i in range(0, len(entity_ht)):\n",
    "                hashtag = hashtag + \",#\" + entity_ht[i]['text']\n",
    "            new_column.append([hashtag])\n",
    "        data_frame = pd.DataFrame(data = new_column, columns=[\"hashtag\"])\n",
    "        # self.count_wordframe(data_frame)\n",
    "        return data_frame\n",
    "    \n",
    "\n",
    "    def twitterhashtage_to_xlsx(self, datframe):\n",
    "        hashtag = self.keyword\n",
    "        today = date.today()\n",
    "        today_str = today.strftime(\"%d%m%Y\")\n",
    "        datframe.to_excel(hashtag+\"_\"+\"hashcount\"+\"_\"+today_str+\".xlsx\", engine=\"openpyxl\", index=False)\n",
    "\n",
    "\n",
    "    def slash_tokenize(self,data):  \n",
    "        result = data.split(\",\")\n",
    "        return result\n",
    "\n",
    "\n",
    "    # def count_wordframe(self, readfile):\n",
    "    def count_wordframe(self):\n",
    "        topic = self.keyword\n",
    "        today = date.today()\n",
    "        today_str = today.strftime(\"%d%m%Y\")\n",
    "        readfile = pd.read_excel(topic+\"_\"+\"hashcount\"+\"_\"+today_str+\".xlsx\")\n",
    "        hastag_data = readfile[\"hashtag\"].dropna()\n",
    "        vectorizer = CountVectorizer(tokenizer = self.slash_tokenize)\n",
    "        transformed_data = vectorizer.fit_transform(hastag_data)\n",
    "        hash_tag_cnt_df = pd.DataFrame(columns = ['word', 'count']) \n",
    "        hash_tag_cnt_df['word'] = vectorizer.get_feature_names()\n",
    "        hash_tag_cnt_df['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "        tophash_tag = hash_tag_cnt_df.sort_values(by=['count'], ascending=False).head(20)\n",
    "        return tophash_tag\n",
    "\n",
    "    def twittercount_to_xlsx(self, datframe):\n",
    "        hashtag = self.keyword\n",
    "        today = date.today()\n",
    "        today_str = today.strftime(\"%d%m%Y\")\n",
    "        datframe.to_excel(hashtag+\"_\"+\"count\"+\"_\"+today_str+\".xlsx\", engine=\"openpyxl\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "    def tokenize_en(self, d):\n",
    "        # print('hey', d)\n",
    "        d = re.sub('[ก-๙]', '', d)\n",
    "        d = re.sub('[0-9]', '', d)\n",
    "        # print('test d', d)\n",
    "        result = d.split(\" \")\n",
    "        result = list(filter(None, result))\n",
    "        return result\n",
    "\n",
    "    def count_word_en(self, dfr):\n",
    "        new_text = []\n",
    "        for txt in dfr[\"tweet\"]:\n",
    "            new_text.append(self.clean_text(txt))\n",
    "        \n",
    "        vectorizer = CountVectorizer(tokenizer=self.tokenize_en)\n",
    "        transformed_data = vectorizer.fit_transform(new_text)\n",
    "        keyword_df_en = pd.DataFrame(columns = ['word', 'count'])\n",
    "        keyword_df_en['word'] = vectorizer.get_feature_names()\n",
    "        keyword_df_en['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "        topword_en = keyword_df_en.sort_values(by=['count'], ascending=False).head(20)\n",
    "\n",
    "        return topword_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n"
     ]
    }
   ],
   "source": [
    "# test = ClawTwitter(\"#REDVELVET\", \"th\")\n",
    "test = ClawTwitter(\"#DREAMCATCHER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>post date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>dcatcherbr</td>\n",
       "      <td>Desde 05/12/2016</td>\n",
       "      <td>2022-04-11 03:16:47</td>\n",
       "      <td>l INSTAGRAM Atualizao da SuA no story sualelbo...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151324965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>deukaenthusiast</td>\n",
       "      <td>☣☠☣</td>\n",
       "      <td>2022-04-11 03:10:17</td>\n",
       "      <td>my friends just bullied me for being active on...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151324802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>deukaemobile</td>\n",
       "      <td>don't repost/claim as yours</td>\n",
       "      <td>2022-04-11 03:06:57</td>\n",
       "      <td>Maison 'MV Teaser' Desktop version hfdreamcatc...</td>\n",
       "      <td>15</td>\n",
       "      <td>63</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151324718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>yoohki_</td>\n",
       "      <td>she they # lesbian # 17</td>\n",
       "      <td>2022-04-11 03:03:05</td>\n",
       "      <td>Dreamcatcher Heardle 15 Dreamcatcher2ndAlbumAp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151324620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>YoohyeonHourly</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-04-11 03:00:00</td>\n",
       "      <td>Dreamcatcher YOOHYEON hfdreamcatcher</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151324543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>JTP_KPOP</td>\n",
       "      <td>JTP ENTERTAINMENT</td>\n",
       "      <td>2022-04-11 00:11:45</td>\n",
       "      <td>Dreamcatcher 'MAISON' MV Teaser</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151320309...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>conundrum329</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-04-11 00:10:08</td>\n",
       "      <td>quote night Dreamcatcher life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151320268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>mellowgona1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-04-11 00:08:47</td>\n",
       "      <td>Flat earthers are claiming this was staged and...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>negative</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151320234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>caramelcream_MY</td>\n",
       "      <td>Dream World</td>\n",
       "      <td>2022-04-11 00:06:33</td>\n",
       "      <td>hfdreamcatcher Dreamcatcher ApocalypseSaveUs</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151320178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>#DREAMCATCHER</td>\n",
       "      <td>dcatcherbr</td>\n",
       "      <td>Desde 05/12/2016</td>\n",
       "      <td>2022-04-11 00:06:02</td>\n",
       "      <td>l VIDEO JiU com Somnias diante da rdio Young S...</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151320165...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic             user                     location  \\\n",
       "0   #DREAMCATCHER       dcatcherbr             Desde 05/12/2016   \n",
       "1   #DREAMCATCHER  deukaenthusiast                          ☣☠☣   \n",
       "2   #DREAMCATCHER     deukaemobile  don't repost/claim as yours   \n",
       "3   #DREAMCATCHER          yoohki_      she they # lesbian # 17   \n",
       "4   #DREAMCATCHER   YoohyeonHourly                      unknown   \n",
       "..            ...              ...                          ...   \n",
       "95  #DREAMCATCHER         JTP_KPOP            JTP ENTERTAINMENT   \n",
       "96  #DREAMCATCHER     conundrum329                      unknown   \n",
       "97  #DREAMCATCHER      mellowgona1                      unknown   \n",
       "98  #DREAMCATCHER  caramelcream_MY                 Dream World    \n",
       "99  #DREAMCATCHER       dcatcherbr             Desde 05/12/2016   \n",
       "\n",
       "             post date                                              tweet  \\\n",
       "0  2022-04-11 03:16:47  l INSTAGRAM Atualizao da SuA no story sualelbo...   \n",
       "1  2022-04-11 03:10:17  my friends just bullied me for being active on...   \n",
       "2  2022-04-11 03:06:57  Maison 'MV Teaser' Desktop version hfdreamcatc...   \n",
       "3  2022-04-11 03:03:05  Dreamcatcher Heardle 15 Dreamcatcher2ndAlbumAp...   \n",
       "4  2022-04-11 03:00:00               Dreamcatcher YOOHYEON hfdreamcatcher   \n",
       "..                 ...                                                ...   \n",
       "95 2022-04-11 00:11:45                    Dreamcatcher 'MAISON' MV Teaser   \n",
       "96 2022-04-11 00:10:08                      quote night Dreamcatcher life   \n",
       "97 2022-04-11 00:08:47  Flat earthers are claiming this was staged and...   \n",
       "98 2022-04-11 00:06:33       hfdreamcatcher Dreamcatcher ApocalypseSaveUs   \n",
       "99 2022-04-11 00:06:02  l VIDEO JiU com Somnias diante da rdio Young S...   \n",
       "\n",
       "    retweet  likes sentiment  \\\n",
       "0         2      3   neutral   \n",
       "1         0      1  positive   \n",
       "2        15     63   neutral   \n",
       "3         0      0   neutral   \n",
       "4         1      4   neutral   \n",
       "..      ...    ...       ...   \n",
       "95        0      1   neutral   \n",
       "96        0      0   neutral   \n",
       "97        1      7  negative   \n",
       "98        1      5   neutral   \n",
       "99        3     18   neutral   \n",
       "\n",
       "                                           tweet link  \n",
       "0   https://twitter.com/twitter/statuses/151324965...  \n",
       "1   https://twitter.com/twitter/statuses/151324802...  \n",
       "2   https://twitter.com/twitter/statuses/151324718...  \n",
       "3   https://twitter.com/twitter/statuses/151324620...  \n",
       "4   https://twitter.com/twitter/statuses/151324543...  \n",
       "..                                                ...  \n",
       "95  https://twitter.com/twitter/statuses/151320309...  \n",
       "96  https://twitter.com/twitter/statuses/151320268...  \n",
       "97  https://twitter.com/twitter/statuses/151320234...  \n",
       "98  https://twitter.com/twitter/statuses/151320178...  \n",
       "99  https://twitter.com/twitter/statuses/151320165...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.show_data(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = test.show_data(test.data)\n",
    "test.twitter_to_xlsx(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teaw\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>dreamcatcher</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>hfdreamcatcher</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apocalypsesaveus</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>maison</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>heardle</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>dreamcatcherndalbumapocalypse</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>apocalypse</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>saveusdreamcatchercomeback</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>save</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>us</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>jiu</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>gahyeon</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>yoohyeon</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>jellyvotesph</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>lvale</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>forward</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>weverse</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>done</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>mv</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>instagram</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              word  count\n",
       "78                    dreamcatcher     59\n",
       "136                 hfdreamcatcher     23\n",
       "16                apocalypsesaveus     14\n",
       "188                         maison     10\n",
       "131                        heardle      9\n",
       "83   dreamcatcherndalbumapocalypse      8\n",
       "15                      apocalypse      8\n",
       "272     saveusdreamcatchercomeback      7\n",
       "270                           save      7\n",
       "336                             us      7\n",
       "159                            jiu      7\n",
       "111                        gahyeon      6\n",
       "362                       yoohyeon      6\n",
       "158                   jellyvotesph      6\n",
       "187                          lvale      6\n",
       "105                        forward      5\n",
       "355                        weverse      5\n",
       "72                            done      5\n",
       "208                             mv      5\n",
       "153                      instagram      4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data = test.show_data(test.data)\n",
    "test.count_word_en(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_data = test.show_data(test.data)\n",
    "# test.count_word_th(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,#TXT,#HUENINGKAI,#TOMORROW_X_TOGEHTER,#휴닝카이,#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,#HUENINGKAI,#TXT,#TOMORROW_X_TOGETHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,#YEONJUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,#TXT_IS_COMING,#TXT,#TOMORROW_X_TOGETHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>,#연준,#수빈,#투모로우바이투게더,#yeonjun,#soobin,#txt,#dra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>,#BTS,#TXT,#ENHYPEN,#HYBE,#HYBEJP_BOYS,#K,#Tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>,#TOMORROW_X_TOGETHER,#투모로우바이투게더,#TXT,#SOOBIN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>,#チョキ,#TXT,#TOMORROW_X_TOGETHER,#JANKEN_X_TOGE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              hashtag\n",
       "0   ,#TXT,#HUENINGKAI,#TOMORROW_X_TOGEHTER,#휴닝카이,#...\n",
       "1              ,#HUENINGKAI,#TXT,#TOMORROW_X_TOGETHER\n",
       "2                                                    \n",
       "3                                           ,#YEONJUN\n",
       "4           ,#TXT_IS_COMING,#TXT,#TOMORROW_X_TOGETHER\n",
       "..                                                ...\n",
       "95                                                   \n",
       "96  ,#연준,#수빈,#투모로우바이투게더,#yeonjun,#soobin,#txt,#dra...\n",
       "97  ,#BTS,#TXT,#ENHYPEN,#HYBE,#HYBEJP_BOYS,#K,#Tak...\n",
       "98  ,#TOMORROW_X_TOGETHER,#투모로우바이투게더,#TXT,#SOOBIN,...\n",
       "99  ,#チョキ,#TXT,#TOMORROW_X_TOGETHER,#JANKEN_X_TOGE...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.data_hashtagcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n"
     ]
    }
   ],
   "source": [
    "hashtag_data = test.data_hashtagcount()\n",
    "test.twitterhashtage_to_xlsx(hashtag_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teaw\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>#txt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>#tomorrow_x_together</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>#we_want_txt_logo</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>#where_is_txt7_logo</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#bighit_give_us_the_logo_please</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>#투모로우바이투게더</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>#you_said_early_may_comeback</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>#taehyun</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>#태현</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>#yeonjun</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>#janken_x_together</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>#soobin</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#hueningkai</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#beomgyu</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>#연준</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#enhypen</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>#사후데이터</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>#โมอาพาโหวต</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>#tomorrow_x_togehter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               word  count\n",
       "0                                       85\n",
       "38                             #txt     52\n",
       "35             #tomorrow_x_together     30\n",
       "44                #we_want_txt_logo     25\n",
       "45              #where_is_txt7_logo     25\n",
       "3   #bighit_give_us_the_logo_please     24\n",
       "75                       #투모로우바이투게더     20\n",
       "48     #you_said_early_may_comeback     15\n",
       "32                         #taehyun     11\n",
       "73                              #태현     10\n",
       "47                         #yeonjun     10\n",
       "17               #janken_x_together      8\n",
       "28                          #soobin      6\n",
       "12                      #hueningkai      6\n",
       "2                          #beomgyu      5\n",
       "71                              #연준      5\n",
       "9                          #enhypen      5\n",
       "64                           #사후데이터      4\n",
       "52                      #โมอาพาโหวต      4\n",
       "34             #tomorrow_x_togehter      4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count_wordframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teaw\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count_wordf = test.count_wordframe()\n",
    "test.twittercount_to_xlsx(count_wordf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>txt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tomorrowxtogether</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>yeonjun</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>whereistxtlogowewanttxtlogobighitgiveusthelogo...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>txtmembers</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>taecyj</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>taehyun</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>txtbighit</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>whereistxtlogowewanttxtlogobighitgiveusthelogo...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>soobin</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>jankenxtogether</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>hueningkai</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>เธอ</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>txttxtmembers</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>beomgyu</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>อา</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>โม</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>เรา</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>moa</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>soyaluvstxt</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  word  count\n",
       "262                                                txt     52\n",
       "252                                  tomorrowxtogether     28\n",
       "298                                            yeonjun     19\n",
       "289  whereistxtlogowewanttxtlogobighitgiveusthelogo...     15\n",
       "268                                         txtmembers     14\n",
       "239                                             taecyj     11\n",
       "240                                            taehyun     11\n",
       "263                                          txtbighit     10\n",
       "288  whereistxtlogowewanttxtlogobighitgiveusthelogo...      9\n",
       "224                                             soobin      8\n",
       "115                                    jankenxtogether      8\n",
       "104                                         hueningkai      7\n",
       "94                                                 เธอ      7\n",
       "272                                      txttxtmembers      7\n",
       "19                                             beomgyu      6\n",
       "83                                                  อา      6\n",
       "114                                                 โม      6\n",
       "100                                                เรา      5\n",
       "156                                                moa      5\n",
       "226                                        soyaluvstxt      5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_th(d):\n",
    "    # print('hey', d)\n",
    "    d = re.sub('[a-z]', '', d)\n",
    "    d = re.sub('[A-Z]', '', d)\n",
    "    d = re.sub('[0-9]', '', d)\n",
    "    # print('test d', d)\n",
    "    result = d.split(\" \")\n",
    "    result = list(filter(None, result))\n",
    "    return result\n",
    "\n",
    "def clean_text_th(text):\n",
    "    # text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    # url = \"https://api.aiforthai.in.th/textcleansing\"\n",
    "    # params = {f'text':{text}}\n",
    "    # headers = {\n",
    "    #     'Apikey': \"REONBZlQhDNoH07AoLRqrOf4dhuAhj9C\",\n",
    "    #     }\n",
    "    # res = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    # # print(res.json())\n",
    "    # return res.json()['cleansing_text']\n",
    "    url ='https://api.aiforthai.in.th/lextoplus'\n",
    "    headers = {'Apikey':\"xxxx\"}\n",
    "    \n",
    "    params = {'text':text,'norm':'1'}\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    return response.json()['tokens']\n",
    "\n",
    "def count_word_en(new_text):\n",
    "# def count_word_en(dfr):\n",
    "    # new_text = []\n",
    "    # for txt in dfr[\"tweet\"]:\n",
    "    #     new_text.append(test.clean_text(txt))\n",
    "    \n",
    "    vectorizer = CountVectorizer(tokenizer=test.tokenize_en)\n",
    "    transformed_data = vectorizer.fit_transform(new_text)\n",
    "    keyword_df_en = pd.DataFrame(columns = ['word', 'count'])\n",
    "    keyword_df_en['word'] = vectorizer.get_feature_names_out()\n",
    "    keyword_df_en['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "    # topword_en = keyword_df_en.sort_values(by=['count'], ascending=False).head(20)\n",
    "\n",
    "    return keyword_df_en\n",
    "\n",
    "def count_word_th(new_text):\n",
    "    # new_text = []\n",
    "    # for txt in dfr[\"tweet\"]:\n",
    "    #     new_text.append(test.clean_text(txt))\n",
    "    \n",
    "    vectorizer = CountVectorizer(tokenizer = tokenize_th)\n",
    "    transformed_data = vectorizer.fit_transform(new_text)\n",
    "    keyword_df_th = pd.DataFrame(columns = ['word', 'count'])\n",
    "    keyword_df_th['word'] = vectorizer.get_feature_names_out()\n",
    "    keyword_df_th['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "    # topword_en = keyword_df_en.sort_values(by=['count'], ascending=False).head(20)\n",
    "\n",
    "    return keyword_df_th\n",
    "\n",
    "\n",
    "dfr = tweets_data\n",
    "new_text_th = []\n",
    "new_text_en = []\n",
    "test_th = [\"วันนี้ฝนไม่ตก\",\"พระอาทิตย์แจ่มใส\"]\n",
    "for txt in dfr[\"tweet\"]:\n",
    "# for txt in test :\n",
    "    new_text_en.append(test.clean_text(txt))\n",
    "    # for txt_cut in pyt_wt(txt, keep_whitespace=False,engine=\"multi_cut\"):\n",
    "    for txt_cut in pyt_wt(txt, keep_whitespace=False,engine=\"multi_cut\"):\n",
    "    # for txt_cut in clean_text_th(txt):\n",
    "    #     if txt_cut == '':\n",
    "    #         pass\n",
    "    #     else:\n",
    "            new_text_th.append(txt_cut)\n",
    "    \n",
    "    # new_text.append(clean_text_th((txt))) \n",
    "\n",
    "# for txt in dfr[\"tweet\"]:\n",
    "#     new_text_en.append(test.clean_text(txt))\n",
    "# new_text = new_text_th + new_text_en\n",
    "# vectorizer = CountVectorizer(tokenizer= tokenize_th)\n",
    "# vectorizer = CountVectorizer(tokenizer=test.tokenize_en)\n",
    "# transformed_data = vectorizer.fit_transform(new_text)\n",
    "# keyword_df_en = pd.DataFrame(columns = ['word', 'count'])\n",
    "# keyword_df_en['word'] = vectorizer.get_feature_names()\n",
    "# keyword_df_en['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "keyword_df_en = count_word_en(new_text_en)\n",
    "keyword_df_th = count_word_th(new_text_th)\n",
    "frames = [keyword_df_en, keyword_df_th]\n",
    "result = pd.concat(frames)\n",
    "\n",
    "topword = result.sort_values(by=['count'], ascending=False).head(20)\n",
    "topword\n",
    "# vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok try 2022-04-01\n",
      "ok except 2022-04-01\n",
      "ok try 2022-04-02\n",
      "ok except 2022-04-02\n",
      "ok try 2022-04-03\n",
      "ok except 2022-04-03\n",
      "ok try 2022-04-04\n",
      "ok except 2022-04-04\n",
      "ok try 2022-04-05\n",
      "ok except 2022-04-05\n",
      "ok try 2022-04-06\n",
      "ok except 2022-04-06\n",
      "ok try 2022-04-07\n",
      "ok except 2022-04-07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>post date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>urorateez</td>\n",
       "      <td>United States</td>\n",
       "      <td>03/04/2022</td>\n",
       "      <td>please see above DREAMCATCHER DREAMCATCHERApoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151040633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>NordskovSomnia</td>\n",
       "      <td>Spain • She/her • Esp/Eng</td>\n",
       "      <td>03/04/2022</td>\n",
       "      <td>DreamCatcher hfdreamcatcher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151040598...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>dcatcherbr</td>\n",
       "      <td>Desde 05/12/2016</td>\n",
       "      <td>03/04/2022</td>\n",
       "      <td>l INFO Na ltima hora BOCA teve mais de mil vis...</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151040543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>O_N_O_Normani</td>\n",
       "      <td>Somewhere</td>\n",
       "      <td>03/04/2022</td>\n",
       "      <td>Dreamcatcher Heardle 7 Dreamcatcher2ndAlbumApo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151040469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>stonefield_DC</td>\n",
       "      <td>unknown</td>\n",
       "      <td>03/04/2022</td>\n",
       "      <td>New Album Release</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151040192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>wonderjazzbar</td>\n",
       "      <td>unknown</td>\n",
       "      <td>07/04/2022</td>\n",
       "      <td>asianjunkiecom hoping to win Dreamcatcher Apoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151182194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>wonderjazzbar</td>\n",
       "      <td>unknown</td>\n",
       "      <td>07/04/2022</td>\n",
       "      <td>symylife i wouldnt mind any ver im indecisive ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151182173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>DCSupportMX</td>\n",
       "      <td>For Dreamcatcher ♥︎</td>\n",
       "      <td>07/04/2022</td>\n",
       "      <td>Tendencia ApocalypseSaveUs y Dreamcatcher son ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151182134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>mistyteez</td>\n",
       "      <td>unknown</td>\n",
       "      <td>07/04/2022</td>\n",
       "      <td>asianjunkiecom Dreamcatcher ApocalypseSaveUs ty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151182121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>#dreamcatcher</td>\n",
       "      <td>joonsutopiax</td>\n",
       "      <td>she/her • desi • UK</td>\n",
       "      <td>07/04/2022</td>\n",
       "      <td>asianjunkiecom tysm for this giveaway Dreamcat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://twitter.com/twitter/statuses/151182087...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic            user                   location   post date  \\\n",
       "0   #dreamcatcher       urorateez              United States  03/04/2022   \n",
       "1   #dreamcatcher  NordskovSomnia  Spain • She/her • Esp/Eng  03/04/2022   \n",
       "2   #dreamcatcher      dcatcherbr           Desde 05/12/2016  03/04/2022   \n",
       "3   #dreamcatcher   O_N_O_Normani                  Somewhere  03/04/2022   \n",
       "4   #dreamcatcher   stonefield_DC                    unknown  03/04/2022   \n",
       "..            ...             ...                        ...         ...   \n",
       "95  #dreamcatcher   wonderjazzbar                    unknown  07/04/2022   \n",
       "96  #dreamcatcher   wonderjazzbar                    unknown  07/04/2022   \n",
       "97  #dreamcatcher     DCSupportMX        For Dreamcatcher ♥︎  07/04/2022   \n",
       "98  #dreamcatcher       mistyteez                    unknown  07/04/2022   \n",
       "99  #dreamcatcher    joonsutopiax        she/her • desi • UK  07/04/2022   \n",
       "\n",
       "                                                tweet retweet likes sentiment  \\\n",
       "0   please see above DREAMCATCHER DREAMCATCHERApoc...       0     0   neutral   \n",
       "1                         DreamCatcher hfdreamcatcher       0     0   neutral   \n",
       "2   l INFO Na ltima hora BOCA teve mais de mil vis...      13    52   neutral   \n",
       "3   Dreamcatcher Heardle 7 Dreamcatcher2ndAlbumApo...       0     0   neutral   \n",
       "4                                   New Album Release       0     1   neutral   \n",
       "..                                                ...     ...   ...       ...   \n",
       "95  asianjunkiecom hoping to win Dreamcatcher Apoc...       0     0  positive   \n",
       "96  symylife i wouldnt mind any ver im indecisive ...       0     0   neutral   \n",
       "97  Tendencia ApocalypseSaveUs y Dreamcatcher son ...       1     6   neutral   \n",
       "98    asianjunkiecom Dreamcatcher ApocalypseSaveUs ty       0     0   neutral   \n",
       "99  asianjunkiecom tysm for this giveaway Dreamcat...       0     0   neutral   \n",
       "\n",
       "                                           tweet link  \n",
       "0   https://twitter.com/twitter/statuses/151040633...  \n",
       "1   https://twitter.com/twitter/statuses/151040598...  \n",
       "2   https://twitter.com/twitter/statuses/151040543...  \n",
       "3   https://twitter.com/twitter/statuses/151040469...  \n",
       "4   https://twitter.com/twitter/statuses/151040192...  \n",
       "..                                                ...  \n",
       "95  https://twitter.com/twitter/statuses/151182194...  \n",
       "96  https://twitter.com/twitter/statuses/151182173...  \n",
       "97  https://twitter.com/twitter/statuses/151182134...  \n",
       "98  https://twitter.com/twitter/statuses/151182121...  \n",
       "99  https://twitter.com/twitter/statuses/151182087...  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_key = \"#NCT127\"\n",
    "date_start = \"01/04/2022\"\n",
    "date_stop = \"07/04/2022\"\n",
    "\n",
    "def formdate(date_start,date_stop):\n",
    "    form_date = \"%d/%m/%Y\"\n",
    "    format_star = datetime.strptime(date_start,form_date)\n",
    "    format_stop = datetime.strptime(date_stop,form_date)\n",
    "    diff_deltadays = format_stop - format_star #timedelta\n",
    "    diff_days = diff_deltadays.days #int\n",
    "    return format_star,format_stop,diff_days\n",
    "\n",
    "def cursor_tweets(date_until):\n",
    "    tweets= tw.Cursor(api.search_tweets, q = topic_key + \" -filter:retweets\" ,until = date_until).items(100)\n",
    "    return tweets     \n",
    "def get_datatweet(tweets):\n",
    "    tweet_list = []    \n",
    "    for tweet in tweets:\n",
    "        tweet_list.append(tweet)\n",
    "    tweets = tweet_list\n",
    "\n",
    "    data_tweet = [[topic_key,\n",
    "                    tweet.user.screen_name,\n",
    "                    tweet.user.location if tweet.user.location != '' else 'unknown',\n",
    "                    datetime.strftime(tweet.created_at.replace(tzinfo = None) + timedelta(hours = 7),\"%d/%m/%Y\"),\n",
    "                    ClawTwitter.remove_url(tweet.text) if tweet.lang == \"en\" else ClawTwitter.remove_url_th(tweet.text),\n",
    "                    tweet.retweet_count,\n",
    "                    tweet.favorite_count,\n",
    "                    test.sentiment(TextBlob(test.stemmer(test.clean_text(ClawTwitter.remove_url(tweet.text)))))\n",
    "                                    if tweet.lang == \"en\" else test.sentiment_th(test.clean_text_th(tweet.text)),\n",
    "                    f\"https://twitter.com/twitter/statuses/{tweet.id}\"] for tweet in tweets]\n",
    "    return data_tweet\n",
    "\n",
    "def show_data(data_tweet:list):\n",
    "    tweet_frame = pd.DataFrame(data=data_tweet,\n",
    "                        columns=['topic', 'user','location','post date', 'tweet','retweet','likes', 'sentiment','tweet link'])\n",
    "    return tweet_frame\n",
    "\n",
    "def twitter_to_xlsx(topic_key,tweets,day_str):\n",
    "    tweets.to_excel(topic_key+\"_\"+ day_str+\".xlsx\", engine=\"openpyxl\", index=False)\n",
    "\n",
    "def select_datatweet(topic_key,start,stop):\n",
    "    topic = topic_key\n",
    "    date_start = start\n",
    "    date_stop = stop\n",
    "    format_star,format_stop,diff_days = formdate(date_start,date_stop)\n",
    "    all_pdtweets = []\n",
    "    for i in range(diff_days+1):\n",
    "        date_add = format_star + timedelta(days = int(i))\n",
    "        date_addstr = date_add.strftime(\"%Y-%m-%d\")\n",
    "        date_filestr = date_add.strftime(\"%d%m%Y\")\n",
    "        try:\n",
    "            print(\"ok try\",date_addstr)\n",
    "            \n",
    "            data_frame = pd.read_excel(topic+\"_\"+date_filestr+\".xlsx\")\n",
    "            # readfile = pd.read_excel(\"#REDVELVET\"+\"_\"+date_opnstr+\".xlsx\")\n",
    "            # print(readfile)\n",
    "        except:\n",
    "            print(\"ok except\",date_addstr)\n",
    "            tweets = cursor_tweets(date_addstr)\n",
    "            data_tweets = get_datatweet(tweets)\n",
    "            data_frame = show_data(data_tweets)\n",
    "            twitter_to_xlsx(topic,data_frame,date_filestr)\n",
    "        all_pdtweets.append(data_frame)\n",
    "    result = pd.concat(all_pdtweets)\n",
    "    # result = reduce(lambda left,right: pd.merge(left,right,how='outer'), all_pdtweets)\n",
    "    # result.to_excel(\"testreduce\"+\".xlsx\", engine=\"openpyxl\", index=False)\n",
    "    return result \n",
    "\n",
    "select_datatweet(topic_key,date_start,date_stop)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e63482132cd177804ad55ee40df4b445c81008446e327e7d6aa26de5f74cb33"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
