{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Teaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Teaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "nltk.download('punkt')   \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime,timedelta ,date\n",
    "# from pythainlp.corpus import thai_stopwords\n",
    "# from pythainlp.tokenize import word_tokenize\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'gOoM90Ig2rs8POa8wxzPgw0oD'\n",
    "consumer_secret= '74vY9D6ZmoMkO4zFFv0uZL9Sl3u2Y7UzibGZqtK1j5bN6agxU5'\n",
    "access_token= '1503736251530170368-rC1gNRmBIgs7HGdgSYuokoUYRKLij6'\n",
    "access_token_secret= '9I8ndE2w6jPVpod5n0YNNS7732VU4stmL8MAjHvcso5xT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClawTwitter:\n",
    "    def __init__(self, keyw:str):\n",
    "        self.listdata = []\n",
    "        self.keyword = keyw\n",
    "        self.data = self.get_datatweet()\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "            auth.set_access_token(access_token, access_token_secret)\n",
    "            api = tw.API(auth)\n",
    "            return api\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "            exit(1)\n",
    "\n",
    "    def remove_url(txt):\n",
    "        \"\"\"Replace URLs found in a text string with nothing \n",
    "        (i.e. it will remove the URL from the string).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        txt : string\n",
    "            A text string that you want to parse and remove urls.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The same txt string with url's removed.\n",
    "        \"\"\"\n",
    "\n",
    "        return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "\n",
    "    def remove_url_th(txt):\n",
    "        \"\"\"Replace URLs found in a text string with nothing \n",
    "        (i.e. it will remove the URL from the string).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        txt : string\n",
    "            A text string that you want to parse and remove urls.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The same txt string with url's removed.\n",
    "        \"\"\"\n",
    "\n",
    "        return \" \".join(re.sub(\"([^\\u0E00-\\u0E7Fa-zA-Z' ]|^'|'$|''|(\\w+:\\/\\/\\S+))\", \"\", txt).split())\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'(@[A-Za-z0-9_]+)', '', text)\n",
    "        text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text_tokens = word_tokenize(text)\n",
    "        text = [word for word in text_tokens if not word in stopwords.words()]\n",
    "        text = ' '.join(text)\n",
    "        return text\n",
    "\n",
    "\n",
    "    def clean_text_th(self, text):\n",
    "        text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "        url = \"https://api.aiforthai.in.th/textcleansing\"\n",
    "        params = {f'text':{text}}\n",
    "        headers = {\n",
    "            'Apikey': \"DXApQFOxFoYXJWd2i0QoCRis4YJfp7az\",\n",
    "            }\n",
    "        res = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "        # print(res.json())\n",
    "        return res.json()['cleansing_text']\n",
    "\n",
    "\n",
    "    def stemmer(self, text):\n",
    "        porter_text = PorterStemmer()\n",
    "        token_words = word_tokenize(text)\n",
    "        stem_word = []\n",
    "        for word in token_words:\n",
    "            stem_word.append(porter_text.stem(word))\n",
    "        return \" \".join(stem_word)\n",
    "\n",
    "\n",
    "    def sentiment(self, text_en):\n",
    "        sentiment_text = text_en.sentiment.polarity\n",
    "        if  sentiment_text > 0:\n",
    "            return 'positive'\n",
    "        elif sentiment_text < 0:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "\n",
    "\n",
    "    def sentiment_th(self, text_th):\n",
    "        url = \"https://api.aiforthai.in.th/ssense\"\n",
    "        params = {'text':text_th}\n",
    "        headers = {\n",
    "            'Apikey': \"DXApQFOxFoYXJWd2i0QoCRis4YJfp7az\"\n",
    "            }\n",
    "        res = requests.get(url, headers=headers, params=params)\n",
    "        if res.json()['sentiment']['polarity'] == '':\n",
    "            polarity = \"neutral\"\n",
    "        else:\n",
    "            polarity = res.json()['sentiment']['polarity']\n",
    "        # print('hey', res.json())\n",
    "        return polarity\n",
    "\n",
    "\n",
    "    def get_datatweet(self):\n",
    "        api = self.connect()\n",
    "        today = datetime.utcnow().date()\n",
    "        today_str = today.strftime(\"%Y-%m-%d\")\n",
    "        tweets = tw.Cursor(api.search_tweets,\n",
    "                    q=self.keyword + \" -filter:retweets\",\n",
    "                    since= today_str).items(100)\n",
    "                    # since= today_str).items(10)\n",
    "                     \n",
    "        tweet_list = []    \n",
    "        for tweet in tweets:\n",
    "            tweet_list.append(tweet)\n",
    "        tweets = tweet_list\n",
    "\n",
    "        data_tweet = [[self.keyword,\n",
    "                        tweet.user.screen_name,\n",
    "                        # tweet.lang,\n",
    "                        tweet.user.location if tweet.user.location != '' else 'unknown',\n",
    "                        tweet.created_at.replace(tzinfo = None) + timedelta(hours = 7),\n",
    "                        ClawTwitter.remove_url(tweet.text) if tweet.lang == \"en\" else ClawTwitter.remove_url_th(tweet.text),\n",
    "                        tweet.retweet_count,\n",
    "                        tweet.favorite_count,\n",
    "                        # self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text))))),\n",
    "                        # self.sentiment(TextBlob(self.stemmer(ClawTwitter.remove_url(tweet.text)))),\n",
    "                        self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text)))))\n",
    "                                        if tweet.lang == \"en\" else self.sentiment_th(self.clean_text_th(tweet.text)),\n",
    "                        # self.sentiment_th(tweet.text) if tweet.lang == \"th\"\n",
    "                        #             else self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text))))),\n",
    "                        f\"https://twitter.com/twitter/statuses/{tweet.id}\"] for tweet in tweets]\n",
    "\n",
    "        return data_tweet\n",
    "\n",
    "\n",
    "    def show_data(self, data_tweet:list):\n",
    "        tweet_frame = pd.DataFrame(data=data_tweet,\n",
    "                            # columns=['topic', 'user','language','location','post date', 'tweet','retweet','likes', 'sentiment','tweet link'])\n",
    "                            columns=['topic', 'user','location','post date', 'tweet','retweet','likes', 'sentiment','tweet link'])\n",
    "        \n",
    "        # tweet_frame.to_excel(f\"{self.keyword}.xlsx\", engine=\"openpyxl\", index=False)\n",
    "        return tweet_frame\n",
    "\n",
    "\n",
    "    def twitter_to_xlsx(self, tweets):\n",
    "        hashtag = self.keyword\n",
    "        today = date.today()\n",
    "        today_str = today.strftime(\"%d%m%Y\")\n",
    "        tweets.to_excel(hashtag+\"_\"+today_str+\".xlsx\", engine=\"openpyxl\", index=False)\n",
    "    \n",
    "\n",
    "    def data_hashtagcount(self):\n",
    "        api = self.connect()\n",
    "        today = datetime.utcnow().date()\n",
    "        today_str = today.strftime(\"%Y-%m-%d\")\n",
    "        new_column = []\n",
    "        for tweet in tw.Cursor(api.search_tweets,\n",
    "                    q=self.keyword + \" -filter:retweets\",\n",
    "                    since= today_str).items(100):\n",
    "            entity_ht = tweet.entities.get('hashtags')\n",
    "            hashtag = \"\"\n",
    "            for i in range(0, len(entity_ht)):\n",
    "                hashtag = hashtag + \",#\" + entity_ht[i]['text']\n",
    "            new_column.append([hashtag])\n",
    "        data_frame = pd.DataFrame(data = new_column, columns=[\"hashtag\"])\n",
    "        return data_frame\n",
    "    \n",
    "\n",
    "    def twitterhashtage_to_xlsx(self, datframe):\n",
    "        hashtag = self.keyword\n",
    "        today = date.today()\n",
    "        today_str = today.strftime(\"%d%m%Y\")\n",
    "        datframe.to_excel(hashtag+\"_\"+\"hashcount\"+\"_\"+today_str+\".xlsx\", engine=\"openpyxl\", index=False)\n",
    "\n",
    "\n",
    "    def slash_tokenize(self,data):  \n",
    "        result = data.split(\",\")\n",
    "        return result\n",
    "\n",
    "\n",
    "    def count_wordframe(self):\n",
    "        topic = self.keyword\n",
    "        today = date.today()\n",
    "        today_str = today.strftime(\"%d%m%Y\")\n",
    "        readfile = pd.read_excel(topic+\"_\"+\"hashcount\"+\"_\"+today_str+\".xlsx\")\n",
    "        hastag_data = readfile[\"hashtag\"].dropna()\n",
    "        vectorizer = CountVectorizer(tokenizer = self.slash_tokenize)\n",
    "        transformed_data = vectorizer.fit_transform(hastag_data)\n",
    "        hash_tag_cnt_df = pd.DataFrame(columns = ['word', 'count']) \n",
    "        hash_tag_cnt_df['word'] = vectorizer.get_feature_names()\n",
    "        hash_tag_cnt_df['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "        tophash_tag = hash_tag_cnt_df.sort_values(by=['count'], ascending=False).head(20)\n",
    "        return tophash_tag\n",
    "\n",
    "    def twittercount_to_xlsx(self, datframe):\n",
    "        hashtag = self.keyword\n",
    "        today = date.today()\n",
    "        today_str = today.strftime(\"%d%m%Y\")\n",
    "        datframe.to_excel(hashtag+\"_\"+\"count\"+\"_\"+today_str+\".xlsx\", engine=\"openpyxl\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "    def tokenize_en(self, d):\n",
    "        # print('hey', d)\n",
    "        d = re.sub('[ก-๙]', '', d)\n",
    "        d = re.sub('[0-9]', '', d)\n",
    "        # print('test d', d)\n",
    "        result = d.split(\" \")\n",
    "        result = list(filter(None, result))\n",
    "        return result\n",
    "\n",
    "    def count_word_en(self, dfr):\n",
    "        new_text = []\n",
    "        for txt in dfr[\"tweet\"]:\n",
    "            new_text.append(self.clean_text(txt))\n",
    "        \n",
    "        vectorizer = CountVectorizer(tokenizer=self.tokenize_en)\n",
    "        transformed_data = vectorizer.fit_transform(new_text)\n",
    "        keyword_df_en = pd.DataFrame(columns = ['word', 'count'])\n",
    "        keyword_df_en['word'] = vectorizer.get_feature_names()\n",
    "        keyword_df_en['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "        topword_en = keyword_df_en.sort_values(by=['count'], ascending=False).head(20)\n",
    "\n",
    "        return topword_en\n",
    "\n",
    "\n",
    "    # def tokenize_th(self, d):\n",
    "    #     # print('hey', d)\n",
    "    #     d = re.sub('[A-Za-z]', '', d)\n",
    "    #     d = re.sub('[0-9]', '', d)\n",
    "    #     # print('test d', d)\n",
    "    #     result = d.split(\" \")\n",
    "    #     # print('re', result)\n",
    "    #     result = list(filter(None, result))\n",
    "    #     return result\n",
    "\n",
    "    # def test_th(self, data):\n",
    "    #     # a = self.tokenize_th(data)\n",
    "    #     url ='https://api.aiforthai.in.th/ssense'\n",
    "    #     headers = {'Apikey':'DXApQFOxFoYXJWd2i0QoCRis4YJfp7az'}\n",
    "    #     params = {'text': data }\n",
    "    #     # res = requests.get(url, headers=headers, params=params)\n",
    "    #     # # print(res.status_code)\n",
    "    #     # # print(res.headers)\n",
    "    #     # print(res.json())\n",
    "    #     res = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    #     # print(res.json())\n",
    "    #     return res.json()['tokens']\n",
    "\n",
    "    # def count_word_th(self, dfr):\n",
    "    #     new_text = []\n",
    "    #     for txt in dfr[\"tweet\"]:\n",
    "    #         new_text.append(self.clean_text_th(txt))\n",
    "    #     # print('test new', new_text)\n",
    "        \n",
    "    #     vectorizer = CountVectorizer(tokenizer=self.tokenize_th)\n",
    "    #     transformed_data = vectorizer.fit_transform(new_text)\n",
    "    #     # count_data = zip(vectorizer.get_feature_names(), np.ravel(transformed_data.sum(axis=0)))\n",
    "    #     keyword_df_th = pd.DataFrame(columns = ['word', 'count'])\n",
    "    #     keyword_df_th['word'] = vectorizer.get_feature_names()\n",
    "    #     keyword_df_th['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "    #     topword_th = keyword_df_th.sort_values(by=['count'], ascending=False).head(20)\n",
    "\n",
    "    #     return topword_th\n",
    "\n",
    "\n",
    "    # def sentiment_th_test(self, text_th):\n",
    "    #     url = \"https://api.aiforthai.in.th/ssense\"\n",
    "    #     params = {'text':text_th}\n",
    "    #     headers = {\n",
    "    #         'Apikey': \"DXApQFOxFoYXJWd2i0QoCRis4YJfp7az\"\n",
    "    #         }\n",
    "    #     res = requests.get(url, headers=headers, params=params)\n",
    "    #     # if res.json()['sentiment']['polarity'] == '':\n",
    "    #     #     polarity = \"neutral\"\n",
    "    #     # else:\n",
    "    #     #     polarity = res.json()['sentiment']['polarity']\n",
    "    #     # print('hey', res.json())\n",
    "    #     # a = res.json()['preprocess']['segmented']\n",
    "    #     print('hey', res.json()['preprocess']['segmented'])\n",
    "    #     return res.json()['preprocess']['segmented']\n",
    "\n",
    "\n",
    "    # def tokenize(self, d):\n",
    "    #     result = d.split(\"/\")\n",
    "    #     result = list(filter(None, result))\n",
    "    #     return result\n",
    "\n",
    "    # def test_w(self, tweet_dataf):\n",
    "    #     new_text = []\n",
    "    #     for txt in tweet_dataf[\"tweet\"]:\n",
    "    #         new_text.append(self.sentiment_th_test(txt))\n",
    "    #     if txt.lang == \"th\":\n",
    "    #         vectorizer = CountVectorizer(tokenizer=self.tokenize)\n",
    "    #         transformed_data = vectorizer.fit_transform(new_text)\n",
    "    #         count_data = zip(vectorizer.get_feature_names(), np.ravel(transformed_data.sum(axis=0)))\n",
    "    #         keyword_df2 = pd.DataFrame(columns = ['word', 'count'])\n",
    "    #         keyword_df2['word'] = vectorizer.get_feature_names()\n",
    "    #         keyword_df2['count'] = np.ravel(transformed_data.sum(axis=0))\n",
    "    #         keyword_df2.sort_values(by=['count'], ascending=False).head(10)\n",
    "    #     return keyword_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "[Errno Expecting value] : 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\requests\\models.py:910\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/site-packages/requests/models.py?line=908'>909</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/site-packages/requests/models.py?line=909'>910</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39;49mloads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/site-packages/requests/models.py?line=910'>911</a>\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/site-packages/requests/models.py?line=911'>912</a>\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/site-packages/requests/models.py?line=912'>913</a>\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\json\\__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/__init__.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/__init__.py?line=354'>355</a>\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/__init__.py?line=355'>356</a>\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/__init__.py?line=356'>357</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/__init__.py?line=357'>358</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=332'>333</a>\u001b[0m \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=333'>334</a>\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=334'>335</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=335'>336</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=336'>337</a>\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=337'>338</a>\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=353'>354</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=354'>355</a>\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/json/decoder.py?line=355'>356</a>\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32md:\\ttx\\softdev2\\cate\\Scraping\\mainprogram\\test\\oldtestCollecttwitter.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39m# test = ClawTwitter(\"#REDVELVET\", \"th\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000004?line=1'>2</a>\u001b[0m test \u001b[39m=\u001b[39m ClawTwitter(\u001b[39m\"\u001b[39;49m\u001b[39m#REDVELVET\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32md:\\ttx\\softdev2\\cate\\Scraping\\mainprogram\\test\\oldtestCollecttwitter.ipynb Cell 4'\u001b[0m in \u001b[0;36mClawTwitter.__init__\u001b[1;34m(self, keyw)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlistdata \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=3'>4</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeyword \u001b[39m=\u001b[39m keyw\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=4'>5</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_datatweet()\n",
      "\u001b[1;32md:\\ttx\\softdev2\\cate\\Scraping\\mainprogram\\test\\oldtestCollecttwitter.ipynb Cell 4'\u001b[0m in \u001b[0;36mClawTwitter.get_datatweet\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=116'>117</a>\u001b[0m     tweet_list\u001b[39m.\u001b[39mappend(tweet)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=117'>118</a>\u001b[0m tweets \u001b[39m=\u001b[39m tweet_list\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=119'>120</a>\u001b[0m data_tweet \u001b[39m=\u001b[39m [[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeyword,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=120'>121</a>\u001b[0m                 tweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39mscreen_name,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=121'>122</a>\u001b[0m                 \u001b[39m# tweet.lang,\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=122'>123</a>\u001b[0m                 tweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39mlocation \u001b[39mif\u001b[39;00m tweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39mlocation \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=123'>124</a>\u001b[0m                 tweet\u001b[39m.\u001b[39mcreated_at\u001b[39m.\u001b[39mreplace(tzinfo \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m+\u001b[39m timedelta(hours \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m),\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=124'>125</a>\u001b[0m                 ClawTwitter\u001b[39m.\u001b[39mremove_url(tweet\u001b[39m.\u001b[39mtext) \u001b[39mif\u001b[39;00m tweet\u001b[39m.\u001b[39mlang \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m ClawTwitter\u001b[39m.\u001b[39mremove_url_th(tweet\u001b[39m.\u001b[39mtext),\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=125'>126</a>\u001b[0m                 tweet\u001b[39m.\u001b[39mretweet_count,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=126'>127</a>\u001b[0m                 tweet\u001b[39m.\u001b[39mfavorite_count,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=127'>128</a>\u001b[0m                 \u001b[39m# self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text))))),\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=128'>129</a>\u001b[0m                 \u001b[39m# self.sentiment(TextBlob(self.stemmer(ClawTwitter.remove_url(tweet.text)))),\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=129'>130</a>\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentiment(TextBlob(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstemmer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean_text(ClawTwitter\u001b[39m.\u001b[39mremove_url(tweet\u001b[39m.\u001b[39mtext)))))\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=130'>131</a>\u001b[0m                                 \u001b[39mif\u001b[39;00m tweet\u001b[39m.\u001b[39mlang \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentiment_th(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean_text_th(tweet\u001b[39m.\u001b[39mtext)),\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=131'>132</a>\u001b[0m                 \u001b[39m# self.sentiment_th(tweet.text) if tweet.lang == \"th\"\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=132'>133</a>\u001b[0m                 \u001b[39m#             else self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text))))),\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=133'>134</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://twitter.com/twitter/statuses/\u001b[39m\u001b[39m{\u001b[39;00mtweet\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=135'>136</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data_tweet\n",
      "\u001b[1;32md:\\ttx\\softdev2\\cate\\Scraping\\mainprogram\\test\\oldtestCollecttwitter.ipynb Cell 4'\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=116'>117</a>\u001b[0m     tweet_list\u001b[39m.\u001b[39mappend(tweet)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=117'>118</a>\u001b[0m tweets \u001b[39m=\u001b[39m tweet_list\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=119'>120</a>\u001b[0m data_tweet \u001b[39m=\u001b[39m [[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeyword,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=120'>121</a>\u001b[0m                 tweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39mscreen_name,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=121'>122</a>\u001b[0m                 \u001b[39m# tweet.lang,\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=122'>123</a>\u001b[0m                 tweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39mlocation \u001b[39mif\u001b[39;00m tweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39mlocation \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=123'>124</a>\u001b[0m                 tweet\u001b[39m.\u001b[39mcreated_at\u001b[39m.\u001b[39mreplace(tzinfo \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m+\u001b[39m timedelta(hours \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m),\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=124'>125</a>\u001b[0m                 ClawTwitter\u001b[39m.\u001b[39mremove_url(tweet\u001b[39m.\u001b[39mtext) \u001b[39mif\u001b[39;00m tweet\u001b[39m.\u001b[39mlang \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m ClawTwitter\u001b[39m.\u001b[39mremove_url_th(tweet\u001b[39m.\u001b[39mtext),\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=125'>126</a>\u001b[0m                 tweet\u001b[39m.\u001b[39mretweet_count,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=126'>127</a>\u001b[0m                 tweet\u001b[39m.\u001b[39mfavorite_count,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=127'>128</a>\u001b[0m                 \u001b[39m# self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text))))),\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=128'>129</a>\u001b[0m                 \u001b[39m# self.sentiment(TextBlob(self.stemmer(ClawTwitter.remove_url(tweet.text)))),\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=129'>130</a>\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentiment(TextBlob(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstemmer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean_text(ClawTwitter\u001b[39m.\u001b[39mremove_url(tweet\u001b[39m.\u001b[39mtext)))))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=130'>131</a>\u001b[0m                                 \u001b[39mif\u001b[39;00m tweet\u001b[39m.\u001b[39mlang \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentiment_th(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclean_text_th(tweet\u001b[39m.\u001b[39;49mtext)),\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=131'>132</a>\u001b[0m                 \u001b[39m# self.sentiment_th(tweet.text) if tweet.lang == \"th\"\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=132'>133</a>\u001b[0m                 \u001b[39m#             else self.sentiment(TextBlob(self.stemmer(self.clean_text(ClawTwitter.remove_url(tweet.text))))),\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=133'>134</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://twitter.com/twitter/statuses/\u001b[39m\u001b[39m{\u001b[39;00mtweet\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=135'>136</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data_tweet\n",
      "\u001b[1;32md:\\ttx\\softdev2\\cate\\Scraping\\mainprogram\\test\\oldtestCollecttwitter.ipynb Cell 4'\u001b[0m in \u001b[0;36mClawTwitter.sentiment_th\u001b[1;34m(self, text_th)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=93'>94</a>\u001b[0m headers \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=94'>95</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mApikey\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDXApQFOxFoYXJWd2i0QoCRis4YJfp7az\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=95'>96</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=96'>97</a>\u001b[0m res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url, headers\u001b[39m=\u001b[39mheaders, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=97'>98</a>\u001b[0m \u001b[39mif\u001b[39;00m res\u001b[39m.\u001b[39;49mjson()[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mpolarity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=98'>99</a>\u001b[0m     polarity \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/ttx/softdev2/cate/Scraping/mainprogram/test/oldtestCollecttwitter.ipynb#ch0000003?line=99'>100</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\requests\\models.py:917\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/site-packages/requests/models.py?line=914'>915</a>\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmessage)\n\u001b[0;32m    <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/site-packages/requests/models.py?line=915'>916</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Teaw/AppData/Local/Programs/Python/Python38-32/lib/site-packages/requests/models.py?line=916'>917</a>\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: [Errno Expecting value] : 0"
     ]
    }
   ],
   "source": [
    "# test = ClawTwitter(\"#REDVELVET\", \"th\")\n",
    "test = ClawTwitter(\"#REDVELVET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test.show_data(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tweets_data = test.show_data(test.data)\n",
    "test.twitter_to_xlsx(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tweets_data = test.show_data(test.data)\n",
    "test.count_word_en(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# tweets_data = test.show_data(test.data)\n",
    "# test.count_word_th(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test.data_hashtagcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hashtag_data = test.data_hashtagcount()\n",
    "test.twitterhashtage_to_xlsx(hashtag_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test.count_wordframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "count_wordf = test.count_wordframe()\n",
    "test.twittercount_to_xlsx(count_wordf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e63482132cd177804ad55ee40df4b445c81008446e327e7d6aa26de5f74cb33"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
